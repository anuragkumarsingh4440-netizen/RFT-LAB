{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA_KQR95hTDB"
      },
      "source": [
        "# RFT-Lab — Input Handling Layer\n",
        "\n",
        "A powerful AI system does not start with a model.\n",
        "It starts with **robust input handling**.\n",
        "\n",
        "This notebook builds a unified input layer that supports:\n",
        "- Text input\n",
        "- PDF documents\n",
        "- Images (OCR)\n",
        "- Audio files\n",
        "- Live microphone speech\n",
        "\n",
        "All inputs are converted into **clean text** before entering\n",
        "the Transformer pipeline.\n",
        "\n",
        "Design principle:\n",
        "Input handling is completely **decoupled** from\n",
        "understanding, reasoning, and generation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiNzSO2lhWqs"
      },
      "source": [
        "## Step 0: Environment Setup\n",
        "\n",
        "We use lightweight, production-friendly libraries.\n",
        "No model logic is mixed here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "W0W5_x8BhaEb",
        "outputId": "778707a6-ec68-41da-ec36-ba032ee67fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.4-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition, pytesseract, PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1 SpeechRecognition-3.14.4 pytesseract-0.3.13\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-gc7138rq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-gc7138rq\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=637f6133fe1437c1a72cbf7a2985cef5fa6dc537d526c624d40ff97a72eaa6af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k5mqjok2/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract PyPDF2 SpeechRecognition\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WEULidnOmz1e",
        "outputId": "f0f8032d-27d6-4b11-aa94-9690dab09448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  libasound2-doc jackd1 portaudio19-doc\n",
            "The following packages will be REMOVED:\n",
            "  libjack-jackd2-0\n",
            "The following NEW packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "  portaudio19-dev\n",
            "0 upgraded, 6 newly installed, 1 to remove and 41 not upgraded.\n",
            "Need to get 596 kB of archives.\n",
            "After this operation, 3,178 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack0 amd64 1:0.125.0-3build2 [93.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libasound2-dev amd64 1.2.6.1-1ubuntu1 [110 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack-dev amd64 1:0.125.0-3build2 [206 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 596 kB in 1s (414 kB/s)\n",
            "dpkg: libjack-jackd2-0:amd64: dependency problems, but removing anyway as you requested:\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            "\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Removing libjack-jackd2-0:amd64 (1.9.20~dfsg-1) ...\n",
            "Selecting previously unselected package libjack0:amd64.\n",
            "(Reading database ... 121679 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjack0_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libasound2-dev:amd64.\n",
            "Preparing to unpack .../1-libasound2-dev_1.2.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libjack-dev.\n",
            "Preparing to unpack .../2-libjack-dev_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack-dev (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "Preparing to unpack .../3-libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../4-libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../5-portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Setting up libjack-dev (1:0.125.0-3build2) ...\n",
            "Setting up libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp312-cp312-linux_x86_64.whl size=68675 sha256=42bd3dca41b760c6d03053a9bec874e06434496a5a17610e62f305116a53316e\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/c7/33/c6a6b210cb5819ec5c219928c794a447742a7d86d21c0b92e6\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y portaudio19-dev\n",
        "!pip install pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YJh1NvBEn3GZ",
        "outputId": "0edab3a4-72f2-4aab-9b28-3e5d8f970477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
            "Downloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install sounddevice scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zoFIB8E8hVCT"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Dict, Union\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import PyPDF2\n",
        "\n",
        "import whisper\n",
        "import speech_recognition as sr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bA2oEKIh2DA"
      },
      "source": [
        "## Step 1: Text Cleaning\n",
        "\n",
        "User inputs are often noisy.\n",
        "We normalize text early to stabilize downstream reasoning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NYD96xGCh12x"
      },
      "outputs": [],
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"[^\\w\\s.,?!]\", \"\", text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siO3lN5Ah5te"
      },
      "source": [
        "## Step 2: Text Input Handling\n",
        "\n",
        "Plain text input is directly cleaned and normalized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yd4hu5TEh1zZ"
      },
      "outputs": [],
      "source": [
        "def handle_text_input(text: str) -> str:\n",
        "    return clean_text(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bomk-f1QiBuu"
      },
      "source": [
        "## Step 3: PDF Input Handling\n",
        "\n",
        "Users upload resumes, reports, or documents.\n",
        "We extract text conservatively and defer interpretation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X27DrOtbh1wD"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(file_path: str) -> str:\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \" \"\n",
        "    return clean_text(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6ITNCZ3iI9q"
      },
      "source": [
        "## Step 4: Image Input Handling\n",
        "\n",
        "Images may contain scanned documents or screenshots.\n",
        "OCR is used to extract readable text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RWCTOxHwh1tf"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_image(image_path: str) -> str:\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return clean_text(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR_DVQlXiQp1"
      },
      "source": [
        "## Step 5: Audio File Input Handling\n",
        "\n",
        "Audio files are converted to text using Whisper.\n",
        "Reasoning never happens on raw audio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr5uD0n1h1qu",
        "outputId": "e76d9eb1-ad6c-47e7-ecf7-bc183d83e2d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:22<00:00, 137MiB/s]\n"
          ]
        }
      ],
      "source": [
        "whisper_model = whisper.load_model(\"large\", device=\"cuda\")\n",
        "\n",
        "def extract_text_from_audio(audio_path: str) -> str:\n",
        "    try:\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        return clean_text(result[\"text\"])\n",
        "    except Exception as e:\n",
        "        return f\"Error transcribing {audio_path}: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNMT2Ll9jMbZ"
      },
      "source": [
        "## Step 6: Live Microphone Input\n",
        "\n",
        "The system also supports real-time microphone input.\n",
        "Users can speak naturally instead of typing.\n",
        "\n",
        "Speech is converted to text and routed\n",
        "into the same pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0VWpLUQuh1oI"
      },
      "outputs": [],
      "source": [
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def record_from_mic() -> str:\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Listening... speak now\")\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    text = recognizer.recognize_google(audio)\n",
        "    return clean_text(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUkKECeojRPB"
      },
      "source": [
        "## Step 7: Unified Input Router\n",
        "\n",
        "Regardless of how input arrives,\n",
        "it is converted into a single normalized format.\n",
        "\n",
        "This function acts as a clean contract\n",
        "between UI and AI core.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uqev7LRDh1lh"
      },
      "outputs": [],
      "source": [
        "def handle_input(\n",
        "    input_type: str,\n",
        "    payload: Union[str, bytes]\n",
        ") -> Dict:\n",
        "\n",
        "    if input_type == \"text\":\n",
        "        content = handle_text_input(payload)\n",
        "\n",
        "    elif input_type == \"pdf\":\n",
        "        content = extract_text_from_pdf(payload)\n",
        "\n",
        "    elif input_type == \"image\":\n",
        "        content = extract_text_from_image(payload)\n",
        "\n",
        "    elif input_type == \"audio\":\n",
        "        content = extract_text_from_audio(payload)\n",
        "\n",
        "    elif input_type == \"mic\":\n",
        "        content = record_from_mic()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported input type\")\n",
        "\n",
        "    return {\n",
        "    \"raw_content\": content,          # actual extracted text\n",
        "    \"length\": len(content.split()),  # word count\n",
        "    \"input_type\": input_type         # source type\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBVPPQ32l35E"
      },
      "source": [
        "## Step 8: Input Validation\n",
        "\n",
        "Before reasoning begins, input quality is checked.\n",
        "Warnings are attached instead of blocking execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7QZnbIrZh1il"
      },
      "outputs": [],
      "source": [
        "def validate_input(input_dict: Dict) -> Dict:\n",
        "    content = input_dict.get(\"raw_content\", \"\")\n",
        "    length = input_dict.get(\"length\", 0)\n",
        "\n",
        "    input_dict[\"is_valid\"] = True\n",
        "    input_dict[\"warning\"] = None\n",
        "\n",
        "    if not content:\n",
        "        input_dict[\"is_valid\"] = False\n",
        "        input_dict[\"warning\"] = \"Empty input\"\n",
        "\n",
        "    elif length < 5:\n",
        "        input_dict[\"warning\"] = \"Input too short for deep reasoning\"\n",
        "\n",
        "    elif length > 5000:\n",
        "        input_dict[\"warning\"] = \"Input very long; truncation may occur\"\n",
        "\n",
        "    return input_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr2WENYdmHsM"
      },
      "source": [
        "## Step 9: End-to-End Test\n",
        "\n",
        "This simulates the exact internal flow\n",
        "of the deployed application.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2uXmCzKh1fx",
        "outputId": "345c5578-8155-4d37-cdc6-03119ec53701"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'raw_content': 'analyze this resume and highlight weaknesses.',\n",
              " 'length': 6,\n",
              " 'input_type': 'text',\n",
              " 'is_valid': True,\n",
              " 'warning': None}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_text = \"Analyze this resume and highlight weaknesses.\"\n",
        "\n",
        "processed = handle_input(\"text\", user_text)\n",
        "validated = validate_input(processed)\n",
        "\n",
        "validated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWWd9z7mmAL"
      },
      "source": [
        "## Microphone Test\n",
        "\n",
        "Speak a sentence and verify text extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "riuGkLLDmoUv"
      },
      "outputs": [],
      "source": [
        "# spoken = handle_input(\"mic\", None)\n",
        "# validated = validate_input(spoken)\n",
        "# validated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnBLnDN6mfdW"
      },
      "source": [
        "## **This notebook demonstrates:**\n",
        "- True multimodal input support\n",
        "- Clean separation of concerns\n",
        "- Production-aware validation\n",
        "- Speech-ready AI system design"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
