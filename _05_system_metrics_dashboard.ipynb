{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrY_Q9rEi884"
   },
   "source": [
    "# RFT-Lab — System Metrics & Transparency\n",
    "\n",
    "A real-world AI system is not trusted\n",
    "just because it gives an answer.\n",
    "\n",
    "It is trusted because it can explain:\n",
    "- how confident it is\n",
    "- how deeply it reasoned\n",
    "- how much internal change happened\n",
    "\n",
    "This notebook builds the **observability layer**\n",
    "of the Reasoning-First Transformer (RFT).\n",
    "\n",
    "No model logic is changed here.\n",
    "We only READ internal signals and expose them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1QoXLpijEvy"
   },
   "source": [
    "## Step 0: Imports\n",
    "\n",
    "We use basic libraries only.\n",
    "No heavy visualization frameworks yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3361,
     "status": "ok",
     "timestamp": 1767119812107,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "5XDrrE9pi68L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YDrrlydjH23"
   },
   "source": [
    "## Step 1: What Do We Measure?\n",
    "\n",
    "We expose three core system metrics:\n",
    "\n",
    "1. Reasoning Depth  \n",
    "   → How many reasoning steps were applied\n",
    "\n",
    "2. Representation Shift  \n",
    "   → How much internal state changed during reasoning\n",
    "\n",
    "3. Confidence Score  \n",
    "   → How stable the final representation is\n",
    "\n",
    "These metrics are:\n",
    "- model-agnostic\n",
    "- lightweight\n",
    "- real-time safe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5C4Vx0ijL4f"
   },
   "source": [
    "## Step 2: Reasoning Depth\n",
    "\n",
    "This metric directly comes from the Reasoning Block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1767119863069,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "zthiqdBljNQ9"
   },
   "outputs": [],
   "source": [
    "def get_reasoning_depth(steps_used):\n",
    "    # Number of reasoning iterations applied\n",
    "    return steps_used\n",
    "# This tells us how much the model actually thought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_O-H45DjU5z"
   },
   "source": [
    "## Step 3: Representation Shift\n",
    "\n",
    "This measures how much the internal state\n",
    "changed due to reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1767119902323,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "XIwM50etjYMB"
   },
   "outputs": [],
   "source": [
    "def get_representation_shift(avg_shift):\n",
    "    # Higher value means more internal transformation\n",
    "    return avg_shift\n",
    "# Large shift = deeper internal change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgE50hHpjeu8"
   },
   "source": [
    "## Step 4: Confidence Estimation\n",
    "\n",
    "Confidence is estimated from representation stability.\n",
    "\n",
    "Less variance → higher confidence\n",
    "More variance → lower confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1767119968025,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "iINPmz9DjjyV"
   },
   "outputs": [],
   "source": [
    "def compute_confidence(reasoned_state):\n",
    "    # Compute variance across feature dimension\n",
    "    variance = torch.var(reasoned_state, dim=-1)\n",
    "\n",
    "    # Average variance across tokens\n",
    "    avg_variance = torch.mean(variance).item()\n",
    "\n",
    "    # Convert variance to confidence score (0–1)\n",
    "    confidence = 1 / (1 + avg_variance)\n",
    "\n",
    "    return round(confidence, 3)\n",
    "\n",
    "    # We don’t guess confidence; we derive it from internal stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLub3xm3ju4C"
   },
   "source": [
    "## Step 5: Risk & Warning Flags\n",
    "\n",
    "We attach simple warnings\n",
    "instead of blocking the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1767120004064,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "KDHhgqWFjxHR"
   },
   "outputs": [],
   "source": [
    "def generate_warnings(depth, confidence):\n",
    "    warnings = []\n",
    "\n",
    "    if depth <= 1:\n",
    "        warnings.append(\"Shallow reasoning used\")\n",
    "\n",
    "    if confidence < 0.4:\n",
    "        warnings.append(\"Low confidence output\")\n",
    "\n",
    "    return warnings\n",
    "# The system admits uncertainty instead of hiding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj74r4mGj3ZX"
   },
   "source": [
    "## Step 6: Metrics Aggregator\n",
    "\n",
    "This function collects all metrics\n",
    "into a single structured output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1767120036911,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "RwwvPCcZj6Qq"
   },
   "outputs": [],
   "source": [
    "def collect_system_metrics(reasoning_result):\n",
    "    depth = get_reasoning_depth(reasoning_result[\"steps_used\"])\n",
    "    shift = get_representation_shift(reasoning_result[\"avg_representation_shift\"])\n",
    "    confidence = compute_confidence(reasoning_result[\"reasoned_state\"])\n",
    "\n",
    "    warnings = generate_warnings(depth, confidence)\n",
    "\n",
    "    return {\n",
    "        \"reasoning_depth\": depth,\n",
    "        \"avg_representation_shift\": round(shift, 4),\n",
    "        \"confidence_score\": confidence,\n",
    "        \"warnings\": warnings\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxUPjRdskAK5"
   },
   "source": [
    "## Step 7: End-to-End Test\n",
    "\n",
    "We simulate output from the Reasoning Block\n",
    "and compute system metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1767120055738,
     "user": {
      "displayName": "Anurag Singh",
      "userId": "12042435789066891421"
     },
     "user_tz": -330
    },
    "id": "8Y9NF4jKkCJq",
    "outputId": "6e9c8fd9-acc8-426b-fead-38dffea835bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning_depth': 3,\n",
       " 'avg_representation_shift': 0.42,\n",
       " 'confidence_score': 0.508,\n",
       " 'warnings': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulated reasoning block output\n",
    "reasoning_output = {\n",
    "    \"reasoned_state\": torch.randn(1, 6, 128),\n",
    "    \"steps_used\": 3,\n",
    "    \"avg_representation_shift\": 0.42\n",
    "}\n",
    "\n",
    "metrics = collect_system_metrics(reasoning_output)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1I4R-nbZkJPj"
   },
   "source": [
    "# **This notebook shows:**\n",
    "- Real-time observability\n",
    "- Explainable AI metrics\n",
    "- Honest confidence reporting\n",
    "- No black-box behavior\n",
    "\n",
    "**The system does not just answer —\n",
    "it explains how much it thought and how sure it is.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqnNMJ93NcnECnxmxJmddO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
